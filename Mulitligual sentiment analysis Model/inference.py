# -*- coding: utf-8 -*-
"""inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aG9W0H5mXCgVN8DfssqkW5xvF1dxwCfO
"""

import torch
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model_path = "/content/drive/MyDrive/Colab Notebooks/my_xlmr_model"
tokenizer = XLMRobertaTokenizer.from_pretrained(model_path)
model = XLMRobertaForSequenceClassification.from_pretrained(model_path)
model.to(device)
model.eval()

def predict_sentiment(text):
  inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)
  inputs = {k: v.to(device) for k,v in inputs.items()}

  with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    preds = torch.argmax(logits, dim=1)

  return preds.item()

# example
text = "meka hari amarui bn"
label = predict_sentiment(text)
print("Predicted Label:", label)