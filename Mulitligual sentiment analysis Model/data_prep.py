# -*- coding: utf-8 -*-
"""data_prep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13tOj-YFJvarq_l93wp4snE1miLydrATZ
"""



import pandas as pd
import torch
from datasets import load_dataset
from sklearn.model_selection import train_test_split
from transformers import XLMRobertaTokenizer

en_dataset = load_dataset("stanfordnlp/sst2", split = "train")
df_en = pd.DataFrame({'text':en_dataset['sentence'], 'label':en_dataset['label']})

si_dataset = load_dataset("DGurgurov/sinhala_sa", split = "train")
df_si = pd.DataFrame({'text':si_dataset['text'], 'label':si_dataset['label']})

df_en.head()

from google.colab import drive
drive.mount('/content/drive')
df_singlish = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Singlish Dataset11 - Singlish Dataset (1).csv")
df_singlish.head()

df_singlish['label'] = df_singlish['label'].map({"Neg": 0, "Pos":1, "Neu":2})
df_singlish.head()

df = pd.concat([df_en, df_si, df_singlish], ignore_index = True)
df= df.sample(frac =1, random_state = 42).reset_index(drop=True)
df.head()


train_df, temp_df = train_test_split(df, test_size = 0.2, random_state= 42, stratify= df["label"])
val_df, test_df = train_test_split(temp_df, test_size = 0.5,random_state= 42, stratify= temp_df["label"])

print("Train size:", len(train_df))
print("Validation size:", len(val_df))
print("Test size:", len(test_df))













